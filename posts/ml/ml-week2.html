<!-- _layouts/default.html -->
<!DOCTYPE html>
<html lang="en">
<head>
  <!-- _includes/head.html -->
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="referrer" content="no-referrer-when-downgrade">
  <title>ML week 2 - yoonzh.com</title>
  <link rel="stylesheet" href="/css/main.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
  <link rel="shortcut icon" href="/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <meta name="apple-mobile-web-app-title" content="ìœ¤å¿—" />
  <link rel="manifest" href="/site.webmanifest" />
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js"
        onload="renderMathInElement(document.body);"></script>
  
  
</head>
</head>
<body class="">
  <!-- _includes/header.html -->
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-K2M9QVQ44D"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-K2M9QVQ44D');
</script>

<header class="site-header">
  <div class="nav-container">
    <div class="logo-group">
      <a href="/" class="logo-image">
        <img src="/images/pepito-square.jpg" alt="Home">
      </a>
      <div class="logo-container">
        <a href="/" class="logo-link">
          <h1 class="logo">ìœ¤å¿—</h1>
        </a>
        <p class="logo-subtitle">[äº‘ ~ ì°Œ]</p>
      </div>
    </div>
    <nav class="nav-links">
      
        <a href="/projects/" class="hover-glow">Projects</a>
      
        <a href="/posts/" class="hover-glow">Posts</a>
      
        <a href="/about/" class="hover-glow">About</a>
      
    </nav>
  </div>
</header>
  
  <main class="page-content">
    <!-- _layouts/post.html -->
<article class="article-detail">
  <!-- _includes/article-content.html -->
<header class="article-header">
  <h1>
    ML week 2
    
  </h1>
  
  <div class="tech-tags">
    
      <span class="tech-tag">ML</span>
    
      <span class="tech-tag">Python</span>
    
  </div>
  
  <div class="article-meta">
    
      <time datetime="2025-02-18T00:00:00+00:00">
        ðŸ“… 2025/02/18
      </time>
    
  </div>
</header>

<div class="article-content">
  <p><em>Adapted from <sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup></em></p>

<h2 id="week-2-tensors--mathematical-foundations">Week 2: Tensors &amp; Mathematical Foundations</h2>
<p><strong>Objective:</strong> Understand tensors, perform tensor operations, and compute gradients using automatic differentiation.</p>

<hr />

<h2 id="key-concepts-explained">Key Concepts Explained</h2>

<h3 id="1-tensors">1. Tensors</h3>

<p><strong>Definition:</strong> A tensor is a multi-dimensional array of numerical values.
<strong>Scalar:</strong> A single number (0D tensor). Example: <code class="language-text highlighter-rouge">5.0</code>.
<strong>Vector:</strong> A 1D array (1D tensor). Example: <code class="language-text highlighter-rouge">[1.0, 2.0, 3.0]</code>.
<strong>Matrix:</strong> A 2D grid (2D tensor). Example: <code class="language-text highlighter-rouge">[[1, 2], [3, 4]]</code>.
<strong>Higher Dimensions:</strong> 3D (cube), 4D (time-series), etc.
<strong>Why Tensors?</strong> They unify data representation for ML models (e.g., images as 3D tensors: height Ã— width Ã— color channels).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="c1"># Create tensors
</span><span class="n">scalar</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)</span>          <span class="c1"># 0D tensor
</span><span class="n">vector</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>    <span class="c1"># 1D tensor
</span><span class="n">matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>  <span class="c1"># 2D tensor
</span></code></pre></div></div>

<h3 id="2-tensor-operations">2. Tensor Operations</h3>

<p><strong>Reshaping:</strong> Change tensor dimensions without altering data.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">reshaped</span> <span class="o">=</span> <span class="n">matrix</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Reshape to 4 rows Ã— 1 column
</span></code></pre></div></div>

<p><strong>Broadcasting:</strong> Automatically expand tensors to perform arithmetic.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>  <span class="c1"># Shape (3,)
</span><span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">10</span><span class="p">],</span> <span class="p">[</span><span class="mi">20</span><span class="p">]])</span>  <span class="c1"># Shape (2, 1)
</span><span class="n">result</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span>  <span class="c1"># Result shape (2, 3)
# [[11, 12, 13], [21, 22, 23]]
</span></code></pre></div></div>

<p><strong>Einsum:</strong> Compact notation for tensor operations (e.g., matrix multiplication).</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]])</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">einsum</span><span class="p">(</span><span class="sh">'</span><span class="s">ij,jk-&gt;ik</span><span class="sh">'</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>  <span class="c1"># Matrix multiplication
# [[19, 22], [43, 50]]
</span></code></pre></div></div>

<h3 id="3-automatic-differentiation-autograd">3. Automatic Differentiation (Autograd)</h3>

<p><strong>Definition:</strong> A technique to automatically compute gradients (derivatives) of functions.</p>

<p><strong>Why Gradients?</strong> Gradients tell us how to adjust model parameters to reduce errors during training.</p>

<p><strong>Example with PyTorch:</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="mf">3.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>  <span class="c1"># Function: y = xÂ² + 2x + 1
</span><span class="n">y</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>  <span class="c1"># Compute gradient dy/dx
</span><span class="nf">print</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>  <span class="c1"># dy/dx = 2x + 2 â†’ 2*3 + 2 = 8.0
</span></code></pre></div></div>

<h3 id="4-jacobian-matrix">4. Jacobian Matrix</h3>

<p><strong>Definition:</strong> A matrix of all first-order partial derivatives of a vector-valued function.</p>

<p><strong>Example Function:</strong> \(\(f(x,y) = [x^2 + 3y, 5x + y^3] \)\)</p>
<ul>
  <li>Jacobian ( J ) has shape (2, 2):<br />
\(\[
J = \begin{bmatrix}
\frac{\partial f_1}{\partial x} &amp; \frac{\partial f_1}{\partial y} \\
\frac{\partial f_2}{\partial x} &amp; \frac{\partial f_2}{\partial y}
\end{bmatrix}
= \begin{bmatrix}
2x &amp; 3 \\
5 &amp; 3y^2
\end{bmatrix}
\]\)
â€”</li>
</ul>

<h2 id="mini-exercises">Mini Exercises</h2>

<h3 id="1-reshape-a-tensor">1. Reshape a Tensor</h3>
<p>Convert a 1D tensor <code class="language-text highlighter-rouge">[1, 2, 3, 4, 5, 6]</code> into a 3x2 matrix.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">tensor</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">reshaped</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<ol>
  <li><strong>Compute Gradients</strong><br />
Use PyTorch to compute the derivative of ( y = 2x^3 + \sin(x) ) at ( x = \pi ).
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="mi">3</span> <span class="o">+</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">y</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">grad</span><span class="p">)</span>  <span class="c1"># dy/dx = 6xÂ² + cos(x) â‰ˆ 6*(9.87) + (-1) â‰ˆ 58.2
</span></code></pre></div>    </div>
  </li>
</ol>

<hr />

<h2 id="project-walkthrough-compute-the-jacobian-matrix">Project Walkthrough: Compute the Jacobian Matrix</h2>

<h3 id="step-1-define-the-function">Step 1: Define the Function</h3>
<p>Compute ( f(x, y) = x^2 + 3y ).</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">y</span>
</code></pre></div></div>

<h3 id="step-2-compute-partial-derivatives-manually">Step 2: Compute Partial Derivatives Manually</h3>
<ul>
  <li>( \frac{\partial f}{\partial x} = 2x )</li>
  <li>( \frac{\partial f}{\partial y} = 3 )</li>
</ul>

<h3 id="step-3-code-the-jacobian">Step 3: Code the Jacobian</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">jacobian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">df_dx</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span>
    <span class="n">df_dy</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([[</span><span class="n">df_dx</span><span class="p">,</span> <span class="n">df_dy</span><span class="p">]])</span>

<span class="c1"># Example at (x=2, y=4)
</span><span class="nf">print</span><span class="p">(</span><span class="nf">jacobian</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>  <span class="c1"># Output: [[4, 3]]
</span></code></pre></div></div>

<h3 id="step-4-visualize-with-numpy">Step 4: Visualize with NumPy</h3>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_vals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y_vals</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">meshgrid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="nf">f</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="c1"># Plot in Jupyter Notebook
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">contourf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">levels</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">f(x, y) = xÂ² + 3y</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">x</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">y</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<hr />

<h2 id="questions">Questions</h2>
<ol>
  <li>What is the rank of a 3x2x4 tensor?</li>
  <li>What does broadcasting allow you to do?</li>
  <li>Compute the gradient of \(\( y = 3x^2 \) at \( x = 2 \).\)</li>
  <li>What is the Jacobian matrix for ( f(x, y) = [x + y, xy] )?</li>
</ol>

<h2 id="dictionary">Dictionary</h2>
<ul>
  <li><strong>Tensor:</strong> A multi-dimensional array of numbers.</li>
  <li><strong>Automatic Differentiation:</strong> Automatically computes gradients for optimization.</li>
  <li><strong>Gradient:</strong> A vector of partial derivatives (slopes) of a function.</li>
  <li><strong>Jacobian Matrix:</strong> A matrix of all first-order partial derivatives of a vector function.</li>
  <li><strong>Reshaping:</strong> Changing the dimensions of a tensor without changing its data.</li>
</ul>

<h2 id="resources">Resources</h2>
<ul>
  <li><strong>NumPy Tutorial:</strong> <a href="https://numpy.org/doc/stable/user/quickstart.html">NumPy Quickstart</a></li>
  <li><strong>PyTorch Autograd:</strong> <a href="https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html">PyTorch Autograd Guide</a></li>
  <li><strong>Visualizing Tensors:</strong> <a href="https://www.3blue1brown.com/topics/linear-algebra">3Blue1Brown Essence of Linear Algebra</a></li>
</ul>

<hr />

<h2 id="tips">Tips</h2>

<ul>
  <li>Use <code class="language-text highlighter-rouge">torch.autograd.functional.jacobian</code> in PyTorch to compute Jacobians automatically for complex functions.</li>
  <li>Debug shape errors by printing tensor shapes (<code class="language-text highlighter-rouge">print(tensor.shape)</code>).</li>
</ul>

<h2 id="answers-to-questions-above">Answers to questions above</h2>
<ol>
  <li>Rank 3 (3 dimensions).</li>
  <li>Perform arithmetic on tensors of different shapes by expanding them.</li>
  <li>( dy/dx = 6x ). At ( x=2 ), gradient = 12.</li>
  <li>( J = \begin{bmatrix} 1 &amp; 1 \ y &amp; x \end{bmatrix} ).</li>
</ol>

<hr />
<h2 id="credits">Credits</h2>

<!--Written by Jorge Porras (2025)-->
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1">
      <p>Deepseek.Â <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

</div>
</article>
  </main>

  <!-- _includes/footer.html -->
<footer class="site-footer">
  <div class="footer-content">
    <div class="social-links">
      <a href="https://github.com/yoon-zh" class="hover-glow" aria-label="GitHub">
        <i class="fab fa-github"></i>
      </a>
      <a href="mailto:yoon_zh@outlook.com" class="hover-glow" aria-label="Email">
        <i class="fas fa-envelope"></i>
      </a>
      <a href="https://www.linkedin.com/in/jorge-porras-1a7393282/" class="hover-glow" aria-label="LinkedIn">
        <i class="fab fa-linkedin"></i>
      </a>
      <a href="https://t.me/yo_o_n" class="hover-glow" aria-label="Telegram">
        <i class="fab fa-telegram-plane"></i>
      </a>
    </div>
    <div class="footer-bottom">
      <p>Â© 2025 ìœ¤å¿—. All rights reserved.</p>
    </div>
  </div>
</footer>
<script src="/scripts/main.js"></script>
<script src="/scripts/codeblocks.js"></script>
<script src="/scripts/axeptio.js"></script>
</body>
</html>